{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5d4fc7d-6214-4883-94fc-f1d7edc6260e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Explanation of the operation of this notebook\n",
    "\n",
    "This notebook is designed to guide the user through a series of specific steps or analysis. Its main functionalities are described below:\n",
    "\n",
    "- ** Import of bookstores: ** The libraries necessary for data analysis and visualization are loaded.\n",
    "- ** Data load: ** The data that will be analyzed along the notebook is imported.\n",
    "- ** Data processing: ** Cleaning, transformation and preparation tasks are carried out for analysis.\n",
    "- ** Exploratory analysis: ** The data is explored through descriptive statistics and visualizations.\n",
    "- ** Modeling or advanced analysis: ** Modeling techniques, Machine Learning or advanced analysis are applied according to the objective of the notebook.\n",
    "- ** Conclusions: ** The findings are summarized and the main conclusions are presented.\n",
    "\n",
    "This document serves as a guide and reference to understand each step made in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f04726fe-3a5e-4f00-977f-98f8dd41d403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74f65c3e-e6c4-4914-a56c-2e45afca4bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "files = spark.read.format(\"binaryFile\").load(landing_zone_path).select(\"path\")\n",
    "\n",
    "for row in files.toLocalIterator():\n",
    "    dbutils.fs.rm(row.path, recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4ef1d6-0453-4bba-9ae4-344fc8179b26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def remove_checkpoints(folder_path):\n",
    "    items = dbutils.fs.ls(folder_path)\n",
    "\n",
    "    for item in items:\n",
    "        dbutils.fs.rm(item.path, recurse=True)\n",
    "\n",
    "remove_checkpoints(folder_path=checkpoint_bronze)\n",
    "remove_checkpoints(folder_path=checkpoint_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f7147c-2d2d-457b-af9d-59d68394951b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE FROM `unalwater_v2`.`default`.`bronze_orders`\n",
      "DELETE FROM `unalwater_v2`.`default`.`silver_orders`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_inconsistencies_report`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_location_customers`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_location_employees`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_performace_operation`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_performance_employees`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_train_model_dataset`\n",
      "DELETE FROM `unalwater_v2`.`default`.`gold_demand_prediction`\n",
      "DELETE FROM `unalwater_v2`.`default`.`bronze_customers`\n",
      "DELETE FROM `unalwater_v2`.`default`.`bronze_employees`\n",
      "DELETE FROM `unalwater_v2`.`default`.`bronze_geodata`\n",
      "DELETE FROM `unalwater_v2`.`default`.`bronze_medellin`\n",
      "DELETE FROM `unalwater_v2`.`default`.`silver_customers`\n",
      "DELETE FROM `unalwater_v2`.`default`.`silver_employees`\n"
     ]
    }
   ],
   "source": [
    "tablas = [Bronze_Orders, Silver_Orders, Gold_Inconsistencies_Report, Gold_Location_Customers, Gold_Location_Employees, Gold_Performance_Operations, Gold_Performance_Employees, Gold_Train_Model_Dataset, 'gold_demand_prediction', Bronze_Customers, Bronze_Employes, Bronze_Geodata, Bronze_Medellin, Silver_Customers, Silver_Employees]\n",
    "\n",
    "for tabla in tablas:\n",
    "    print(f\"DELETE FROM `unalwater_v2`.`default`.`{tabla}`\")\n",
    "    spark.sql(f\"DELETE FROM `unalwater_v2`.`default`.`{tabla}`\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean directories and tables",
   "widgets": {}
  },
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "5d727189-ca80-47e8-b94d-a7289df703a2",
    "default_lakehouse_name": "unalwater",
    "default_lakehouse_workspace_id": "19f7c29b-83a9-42bb-812f-ef7bfc71c961",
    "known_lakehouses": [
     {
      "id": "5d727189-ca80-47e8-b94d-a7289df703a2"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "es"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
