{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba31abd3-427b-43e4-9a4c-e93442ae1732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%run ../DataProcesing/Transversal/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7bdd6f-fab3-4bb8-93bb-33b51587b300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "\n",
    "df  = spark.table(Silver_Orders)\n",
    "\n",
    "df = df.select(\n",
    "    to_date(\"event_date\", \"dd/MM/yyyy HH:mm:ss\").alias(\"event_date\"),\n",
    "    \"neighborhood\",\n",
    "    \"quantity_products\")\n",
    "\n",
    "df = df.filter(~col(\"neighborhood\").isin(\"None\", \"DESCONOCIDO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834abb45-e9f5-4a30-a028-971dc71aeff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, dayofweek\n",
    "\n",
    "\n",
    "df_agg = df.groupBy(\"neighborhood\", \"event_date\")\\\n",
    "           .agg(sum(\"quantity_products\").alias(\"quantity_products\"))\n",
    "\n",
    "df_agg = df_agg.withColumn(\"day_number\", dayofweek(\"event_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22bcea17-9d12-4ab9-9e04-0f5805604c5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, avg, when\n",
    "\n",
    "\n",
    "windowSpec = Window.partitionBy(\"neighborhood\").orderBy(\"event_date\")\n",
    "windowSpec_2d = windowSpec.rowsBetween(-2, -1)  # 2 days ago\n",
    "\n",
    "df_enrichment = df_agg.withColumn(\"demand_lag_1\", lag(\"quantity_products\", 1).over(windowSpec))\\\n",
    "                      .withColumn(\"demand_lag_2\", lag(\"quantity_products\", 2).over(windowSpec))\n",
    "\n",
    "df_enrichment = df_enrichment.withColumn(\"avg_demand_2d\", avg(\"quantity_products\").over(windowSpec_2d))\n",
    "\n",
    "df_enrichment = df_enrichment.fillna({\n",
    "    \"demand_lag_1\": 0,\n",
    "    \"demand_lag_2\": 0,\n",
    "    \"avg_demand_2d\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"b5b5de8a-34d1-456b-b86f-fc376caf8be0\",\"activityId\":\"3e6ff5a1-29ef-4d7b-b199-0d5cfe8f03f2\",\"applicationId\":\"application_1753749395153_0001\",\"jobGroupId\":\"49\",\"advices\":{\"info\":1}}"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32bd3b7f-5918-4174-b2fb-337e9db08563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "df_enrichment.write\\\n",
    "             .mode(\"overwrite\")\\\n",
    "             .option(\"overwriteSchema\", \"true\")\\\n",
    "             .saveAsTable(Gold_Train_Model_Dataset)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Preprocessing",
   "widgets": {}
  },
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "5d727189-ca80-47e8-b94d-a7289df703a2",
    "default_lakehouse_name": "unalwater",
    "default_lakehouse_workspace_id": "19f7c29b-83a9-42bb-812f-ef7bfc71c961",
    "known_lakehouses": [
     {
      "id": "5d727189-ca80-47e8-b94d-a7289df703a2"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "es"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
